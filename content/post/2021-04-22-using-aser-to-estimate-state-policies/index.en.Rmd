---
title: Using ASER to estimate state policies
author: ''
date: '2021-08-16'
slug: []
bibliography: ../sampling.bib
draft: true
categories: []
tags: 
  - education
---

In a [recent article]( https://www.sciencedirect.com/science/article/pii/S0738059321000626) Andres Parrado and I take a look at the two main sources of learning outcomes data in India -- NAS and ASER -- and conclude that a) NAS data is (most likely) completely unreliable and b) ASER data, while reliable, is a bit noisy. 

The implications for people considering using NAS data are pretty clear -- you **shouldn't**. For ASER, the implications are a bit murkier. In the paper, we say that analysts should probably avoid using ASER data at the district level (which the ASER Centre already recommended) and that they should be careful about comparing year-on-year changes between states. One topic we didn't really touch is whether ASER data can be used to evaluate the impact of state-level policies. This is a tough question to answer because it depends not just on the level of noise in the ASER data but also on the methodology used and other aspects of the data. 

One way to figure out whether ASER can be used to evaluate state-level policies is to take a stab at using it to evaluate state-level policies and see what happens. In this blog post, I attempt to do exactly that by using ASER to estimate the impact of Haryana’s Quality Improvement Programme using a synthetic control approach. The upshot of the analysis is that, even if we fudge the start date for the programme, we can’t confidently say that the reform had any impact on learning outcomes.

To be clear, I am not saying that the Haryana reforms had no impact. Rather, I am saying that this analysis which uses the best methods and the best data we have available provides absolutely no evidence that it had an impact. Lastly, I apologize for picking on BCG a bit in this post. BCG just did what we all do – paint our own efforts in the best light possible. 

# The Haryana Quality Improvement Programme

I chose Haryana for this analysis because they seem to have spent more effort reforming their education system over the past ten years than any other state. (That is a subjective assessment on my part, but it certainly does seem like they generated more press and attention with their ed reforms than any other state.) In 2014, Haryana launched the “Quality Improvement Programme” (QIP), an ambitious project to improve learning in the states’ government schools through a variety of measures including monthly student assessments, teacher training, school consolidation, and leadership training. See [here]( https://www.business-standard.com/article/pti-stories/haryana-to-start-quality-improvement-programme-in-schools-114050800695_1.html) for details. 

In [two]( https://www.bcg.com/industries/education/transforming-education-on-massive-scale) [articles]( https://www.bcg.com/publications/2017/education-social-impact-breakthrough-education-reform-in-india) on their website, Boston Consulting Group (BCG), the strategic partner on the QIP project, claim that QIP led to a massive increase in learning outcomes. According to one of the articles: 

“The impact of the reforms in Haryana has exceeded expectations. From 2012 through 2014, as the overhaul was being rolled out, the share of fifth graders who could do division increased 5% and the share who could read a standard second-grade text jumped 10%. That was quite a reversal: from 2010 through 2012, the share of fifth graders who could do division had fallen 26%, and the share of children who could read a standard second-grade text had dropped 17%. According to the National Achievements Survey report published in January 2016, Haryana was one of just two states in India that showed improvement in learning outcomes across all subjects, with 28 of the 30 Indian states posting declines or no change.”

# A Closer Look at BCG’s Claim

The BCG articles claiming that QIP led to massive increases in learning outcomes mix and match data from ASER, NAS, and EI and learning outcomes from different grades. A more serious issue with the analysis that they claim that learning gains between 2012 and 2014 are due to QIP despite the fact that, by BCG’s own account, QIP started in 2014. 

If we look at ASER data for Haryana from 2006 to 2018, it’s easy to see why they fudged the start date a bit. If we just look at the period between 2012 and 2014, the learning gains in Haryana do indeed look impressive!

<< insert figure>>

Yet, if we compare these gains with gains from other states, it’s unclear whether even with the fudged start date QIP clearly led to learning gains in Haryana. While ASER scores increased between 2012 and 2014 in Haryana, they increased just as much in other states too. Clearly, we need a more rigorous approach to estimating impact.

# Using the Synthetic Control Method to Estimate the Impact of QIP

In the code below, I estimate the effect of QIP, under the assumption that QIP started in 2012 and ended in 2014. The synthetic control method offers a more rigorous approach to the classic single unit case study.  Traditionally, when attempting to estimate the impact of a policy implemented in only one state or region, researchers would pick one other state or region to use as the control. This approach is obviously fraught.  States may vary significantly in their policies and trends over time and thus it is questionable whether any one state would serve as a good control for another state. 

The synthetic control method seeks to create a better control for the state in which the policy or intervention has been implemented by using a weighted average of the outcomes for several other states which display similar trends in the outcome prior to the intervention and have similar covariate values. [Abadie, Diamond, and Hainmuller (2011)](https://www.tandfonline.com/doi/pdf/10.1198/jasa.2009.ap08746) show that the if this "synthetic control" matches the intervention state in terms of pre-intervention outcomes and covariates, and outcomes are determined by a factor model (see article for more details), the synthetic control will likely do a good job of predicting the outcome in the intervention state after the implementation of the intervention. 
A second advantage of the synthetic control approach is that it provides a natural way to test the reliability of our estimate through the use of placebo tests. For example, we may conduct a set of placebo test by dropping the intervention state from our sample and then calculating the "effect" for each of the other states. By comparing the size of the effect for the actual intervention state with the size of the placebo effects for the other states, we may get a sense of how robust our estimate is. 

[Abadie (2019)](https://economics.mit.edu/files/17847) provides an excellent overview of the method and [Abadie et al (2011)](https://dspace.mit.edu/handle/1721.1/71234) provides clear guidance on how to use the approach in R.

# Details of the Synthetic Control Approach

I use SCM to estimate the impact of QIP on grade 5 reading levels in Haryana in 2013 and 2014. I use grade 5 reading levels as the outcome because it allows me to use grade 3 reading levels from the previous round as a covariate which should increase my precision substantially. There is now a cottage industry of synthetic control approaches. I use the original synthetic control approach as described in Abadie, Diamond, and Hainmuller due to the availability of the R Synth package to apply this approach. 

To apply the synthetic control approach, we must specify a set of predictors and a set of linear combinations of the pre-intervention outcomes variables to generate the synthetic control match. For predictors, I use grade 3 reading scores in 2012, the mean of grade 5 reading scores from 2010 to 2012, the mean of grade 3 math scores from 2007 to 2012, and the mean of grade 5 math scores from 2007 to 2012. Other details can be found in the code below.
Results
The graphs below show the estimated effect, based on SCM, for all states in 2013 and 2014. While the effect for Haryana is positive for both years the estimated effect in 2013 is smaller than the estimated placebo effect for 3 other states and smaller than the estimated placebo effect for 4 other states in 2014. Since the estimated effect is significantly smaller than several of the placebo effects we can’t be confident that the estimated effect is in fact a true effect. 

# Postscript

In late 2017, Haryana launched “Saksham Ghoshna,” an equally ambitious follow-up project to QIP which also included regular student assessments as well as new dashboards and several other pedagogic interventions. Ironically, one of the officials involved [claimed]( https://yourstory.com/socialstory/2019/02/haryana-transformed-student-learning/amp) that “If we look at NCERT’s various National Achievement Survey (NAS) and ASER reports, the surveys point out that the quality of school education in the state has been going down for years. Government school teachers in Haryana are well-qualified but somehow the link is missing. Classroom studies have not being meaningful. This was the initiation point.”

